---
title: juc复习
date: 2025-03-08 18:03:57
tags:

---

# juc并发

## 基础

### 优缺点

- 为什么要用到并发

	- 充分利用多核cpu的运算能力

	- 方便业务拆分

- 缺点

	- 频繁的上下文切换

	- 线程安全（避免死锁）

- 易混淆

	- 同步VS异步

		- 同步方法调用一开始，调用者必须等待被调用的方法结束后，调用者后面的代码才能执行。

		- 异步调用，指的是，调用者不用管被调用方法是否完成，都会继续执行后面的代码，当被调用的方法完成后会通知调用者。

	- 并发与并行

		- 并发指的是多个任务交替进行

		- 并行则是指真正意义上的“同时进行”

	- 阻塞和非阻塞

		- 非阻塞就恰好相反，它强调没有一个线程可以阻塞其他线程，所有的线程都会尝试地往前运行

		- 一个线程占有了临界区资源，那么其他线程需要这个资源就必须进行等待该资源的释放，会导致等待的线程挂起，这种情况就是阻塞

	- 临界区

		- 用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每个线程使用时，一旦临界区资源被一个线程占有，那么其他线程必须等待

### 进程和线程

- 进程：程序的运行过程，资源分配的最小单位

- 线程：属于进程的一部分，资源调度的基本单位

	- 线程共享

		- 堆：存储所有对象

		- 方法区(1.8后叫做元空间)

			- 类信息

			- 常量

			- 静态变量

		- 直接内存

	- 线程私有

		- 程序计数器

			- 系统根据程序计数器依次读取指令

			- 多线程下，记录当前线程执行的位置，线程切换后可以知道线程的执行位置

		- 虚拟机栈(存储栈帧)

			- java方法执行之前会创建一个栈帧，方法结束后栈帧就会出栈

			- 栈帧

				- 局部变量表

				- 操作数栈

				- 常量池引用

		- 本地方法栈（针对于native方法）

### 线程的状态和基本操作

- 如何新建线程

	- 继承Thread类

	- 实现Runnable接口

	- 实现Callable接口

	- 线程池创建

- 线程状态的转换

	- new

		- 初始状态，未start

	- runnable

		- 运行状态

	- blocked

		- 阻塞，被锁影响

	- waitting

		- 等待状态， 调用wait(),join()进入,等待notify唤醒变成runnable

	- time_waiting

		- 有时间的等待状态

	- terminated

		- 终止状态

	-  

- 基本操作

	- interrput 一个运行中的线程是否被其他线程进行了中断操作

		- interrupt 中断该线程，在sleep后调用interrupt会抛出InterruptedException

		- isInterrputed 判断该线程对象是否被中断，标志位不会清除

		- interrputed 判断该线程是否被中断，标志位会被清除

		- 调用 interrupt 是如何让线程抛出异常的

			- 每个线程都一个与之关联的布尔属性来表示其中断状态，中断状态的初始值为false，当一个线程被其它线程调用Thread.interrupt()方法中断时，会根据实际情况做出响应。

			- 1.如果该线程正在执行低级别的可中断方法（如Thread.sleep()、Thread.join()或Object.wait()），则会解除阻塞并抛出InterruptedException异常。

			- 2.否则Thread.interrupt()仅设置线程的中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。

	- sleep 让当前线程按照指定的时间休眠(如果当前线程获得了锁，不会失去)

		- 与wait的区别

			- sleep()方法是Thread的静态方法，而wait是Object实例方法

			- wait()方法必须要在同步方法或者同步块中调用，而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；

			- sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。

	- wait 线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 唤醒

	- join 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。

	- yield 一旦执行，它会使当前线程让出CPU， sleep不会让出cpu

- 守护线程 Daemon

	- 守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。

	- 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。（main是非守护线程）

### 如何停止一个线程的运行

- 异常法停止：线程调用interrupt()方法后，在线程的run方法中判断当前对象的interrupted()状态，如果是中断状态则抛出异常，达到中断线程的效果。

- 在沉睡中停止：先将线程sleep，然后调用interrupt标记中断状态，interrupt会将阻塞状态的线程中断。会抛出中断异常，达到停止线程的效果

- stop()暴力停止：线程调用stop()方法会被暴力停止，方法已弃用，该方法会有不好的后果：强制让线程停止有可能使一些请理性的工作得不到完成。

- 使用return停止线程：调用interrupt标记为中断状态后，在run方法中判断当前线程状态，如果为中断状态则return，能达到停止线程的效果。

### 可以直接调用 Thread 类的 run 方法吗？

- Thread对象调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

## JMM内存模型

### 定义

- 并发编程相关的一组规范

	- 抽象了线程和主内存之间的关系

		-  

			- 线程之间的共享变量必须存储在主内存中。

	- 规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范

### 解决的问题

- 主存与本地内存数据不一致

- 重排序

	- 概念

		- 系统在执行代码的时候并不一定按照写的代码顺序依次执行

	- 三种重排序

		- 1.编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；

		- 2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；插入内存屏障

		- 3.内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的

	-  

	- 问题

		- 指令重排序可以保证串行语义一致，但可能会导致多线程间的语义不一致

			- java中可以通过volatile来禁止指令重排序优化

				- volatile通过内存屏障来禁止指令重排

	- as-if-serial

		- 不管怎么重排序（编译器和处理器为了提供并行度），（单线程）程序的执行结果不能被改变。

### happens-before

- 定义

	- 如果A happens-before ,而且A的执行顺序排在BB 之前

	- 如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，则指令可以重排序

- 向程序员提供跨线程的内存可见性保证（内存屏障）

- 具体规则

	- 程序顺序

	- volatle变量

	- 监视器锁

	- start

	- join

	- 线程中断

	- 对象finnalize

### 并发编程三大特性

- 原子性

	- 用synchronized，Lock，原子类实现

- 可见性

	- 用volatile，synchronized,Lock实现

- 有序性

	- 指令重排序问题，用volatile关键字禁止重排序问题

### volatile 关键字

- 作用

	- 1.保证变量可见性，令线程每次去主存读取数据，而不是读取线程内的数据副本

	- 2.禁止指令重排序，通过插入特定的内存屏障 的方式来禁止指令重排序。

- 缺点：只能保证单一变量可见性，不能保证原子性

- 禁止指令重排序的使用案例

	- 双重校验锁实现对象单例（线程安全）

	- 示例代码

	  public class Singleton {
	  
	  //这里uniqueInstance修饰是因为，uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：
	  为 uniqueInstance 分配内存空间
	  初始化 uniqueInstance
	  将 uniqueInstance 指向分配的内存地址
	  这里可能会发生指令重排序变为1->3->2,在多线程情况下可能会出现有线程获取到未初始化的对象。
	      private volatile static Singleton uniqueInstance;
	  
	      private Singleton() {
	      }
	      
	      public  static Singleton getUniqueInstance() {
	         //先判断对象是否已经实例过，没有实例化过才进入加锁代码
	          if (uniqueInstance == null) {
	              //类对象加锁
	              synchronized (Singleton.class) {
	                  if (uniqueInstance == null) {
	                      uniqueInstance = new Singleton();
	                  }
	              }
	          }
	          return uniqueInstance;
	      }
	  }
	  
	  
## ThreadLocal

### 描述：线程本地变量，操作自己本地内存里面的变量，起到线程隔离作用

### 实现方式

- 每个线程持有一个threadLocalMap

	- key: ThreadLocal(弱引用)

	- value: Object

- 每次为线程绑定新的变量时需要创建一个threadLocal,调用threadLocal.set(value)去绑定

	- ThreadLocal.set()

		-  

	- ThreadLocal.get()

		-  

### 内存泄露问题

- 问题描述：key为threadlocal的弱引用，value为强引用，当key没有被外部强引用时，key会被清理掉，value并不会

- 解决方案：threadlocal中set(),get(),remove()方法都会清理key为Null的entry,但是我们最好还是手动调用一下remove()。

	- key弱引用这样设计就是为了避免无用的线程占用资源，实现资源利用最大化

## 锁的分类

### 乐观锁和悲观锁

- 悲观锁

	- 描述: 共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。

	- 实现方式

		- synchronized

		- Reentranlock

- 乐观锁

	- 描述: 共享资源可以给多个线程使用，提交时再判断

	- 实现方式

		- 版本号机制

		- CAS算法

			- 概念:  Compare And Swap（比较与交换）

			- 底层实现

				- 依赖于一条 CPU 的原子指令

				- CAS 涉及到三个操作数：

V：要更新的变量值(Var)
E：预期值(Expected)
N：拟写入的新值(New)

			- 缺点
	
				- "ABA"问题，可以通过加版本号和时间戳解决
	
				- 循环时间长开销大
	
				- 只能保证一个共享变量的原子操作

### 公平锁

- 非公平锁

	- 不会进行排队，通过插队获取锁

	- NoFairSync

- 公平锁

	- 按照排队顺序获取锁

	- FairSync

### 从资源锁定，线程是否阻塞

- 阻塞

	- 等待解锁重试

- 不阻塞

	- 自旋锁

		- 优点

			- 不需要内核切换

			- 短时间占用提升程序运行效率

		- 缺点

			- 无法保证锁的公平性

			- 长时间占用锁，浪费CPU

	- 适应性自旋锁

		- 根据上次自旋锁锁定时间和锁状态决定

## sychnorized

### 使用场景

- 修饰代码块(锁指定对象/类)

- 修饰静态方法(锁当前类)

- 修饰实例方法(锁当前对象实例)

### moniter机制

- 加锁执行monitorener指令

- 释放锁执行monitorexi指令

- 锁的重入性：同一个锁，并不需要再次申请获取锁

### 内存语义

- 共享变量会刷新到主存中，线程每次从主存中读取最新的值到自身的工作内存中

### 锁优化

- 锁的级别

	- 无锁状态

		- Mark Word中的内容

	- 偏向锁状态

		-  

			- 场景：一个线程对一个锁多次获取的情况

	- 轻量级锁状态

		-  

			- 场景：执行体比较简单(即减少锁的粒度或时间)，自旋一会就可以获取到锁

	- 重量级锁状态

		-  

			- 依赖操作系统的原生线程，唤起或挂起线程开销很大。用户态->内核态的切换

- 对象在内存中的布局

	- 对象头

		- MarkWord: 用于存储对象自身的运行时数据

			- hashcode 25bit

			- GC分代年龄 4bit

			- 锁状态标志 1bit

			- 线程持有的锁等 2bit

		- 类型指针: 确定该对象是哪个类的实例

		- 数组的长度(如果当前对象是数组

	- 实例数据

	- 对齐填充

- 锁消除

	- 如果当前没有其他线程一起执行的话，则将代码所属的同步锁消除

- 锁粗化

	- 将多个连在一起的锁扩展成一个范围更大的锁

- cas自旋

### 锁的升级的过程(不会降级)

- 1.无锁

	- 当一个线程第一次访问一个对象的同步块时，JVM会在对象头中设置该线程的Thread ID，并将对象头的状态位设置为“偏向锁”。这个过程称为“偏向”，表示对象当前偏向于第一个访问它的线程。

- 2.线程尝试通过CAS修改对象头Mark Word中的线程id

	- success: 继续获取到锁

	- fail:  升级为轻量级锁

- 3.线程尝试使用CAS修改对象头中的Mark Word替换为指向线程栈中锁记录的指针

	- success: 获取到锁

	- fail:检查是否自己已获取到，否则进行自旋获取锁，当自选次数达到临界值，升级为重量级锁

- 4.重量级锁使用操作系统互斥量mutex来实现传统锁，其他竞争的线程不会自旋了，而是直接阻塞

-  

## ReentrantLock

### 描述：实现了Lock接口，增加了轮询，超时，中断，公平锁和非公平锁等高级功能

### 特点

- 可重入锁

- 默认非公平锁(通过构造函数设置)

### 与synchronized的区别

- 等待可中断

- 可实现公平锁

- 可实现选择性通知(Condiction类，锁可以绑定多个条件)

### 底层实现AQS

- 描述:AbstractQueuedSynchronizer（抽象队列同步器），是一个抽象类，主要用来构建锁和同步器

- 数据结构

	- int成员变量state表示同步状态，使用volatile修饰，通过内置的线程等待队列来完成资源线程的排队工作。

		- 未锁定状态state=0,当线程获取到锁以后，将state+1,支持可重入（State会累加），但注意什释放时也会释放多次，直到为0。

	- FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）

- 核心思想

	- 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态，将暂时获取不到锁的线程加入到阻塞队列中，通过自旋不断尝试获取锁。

		-  

- 源码解析

	- 获取锁

		- 公平

			- 调用tryAcquire()方法索取锁，如果没有排队的线程而且使用CAS方法成功把状态从0变1，则获取锁成功，如果当前已经上锁的话，判断当前线程是不是获取锁的线程，不是则通过调用addWatier把当前线程和Node节点进行封装，判断尾节点，存在则插入同步队列，否则成为第一个等待线程，调用acquireQueued方法进行自旋，判断给定节点的先驱节点是不是头节点，如果是头指针指向当前节点则释放前驱节点，唤醒后继节点

				-  

		- 非公平

			- 非公平锁在加锁前会直接使用 CAS 操作设置同步状态，如果设置成功，就会把当前线程设置为偏向锁的线程；

				-  

			-  CAS 操作失败直接执行 tryAcquire 方法，读取线程同步状态，如果未加锁会使用 CAS 再次进行加锁，不会等待 hasQueuedPredecessors 方法的执行，达到只要线程释放锁就会加锁的目

		- 简化流程

			- 如果 lock 加锁设置成功，设置当前线程为独占锁的线程；如果 lock 加锁设置失败，还会再尝试获取一次锁数量，

			- 如果锁数量为0，再基于 CAS 尝试将 state（锁数量）从0设置为1一次，如果设置成功，设置当前线程为独占锁的线程；

			- 如果锁数量不为0或者上边的尝试又失败了，查看当前线程是不是已经是独占锁的线程了，如果是，则将当前的锁数量+1；如果不是，则将该线程封装在一个Node内，并加入到等待队列中去。等待被其前一个线程节点唤醒。

	- 释放锁

		- 调用tryRelease方法释放锁，判断当前同步锁的重入次数 - 1 是否大于 > 1，是的话解锁失败，否则判断当前线程是否是独占锁的线程，释放独占锁，调用unparkSuccessor 唤醒后继线程

			-  

- 具体实例

	- CountDownLatch（一次性使用）

		- 作用

			- 允许count个线程阻塞在一个地方，直至所有线程的任务都执行完毕

		- 原理

			- 默认构造AQS的state值为count

			- 线程执行完毕修改state值

			- countDown()以CAS操作减少state，直至state为0

			- 调用await()方法时

				- 如果state>0主线程阻塞

				- 如果state=0或主线程中断,主线程继续执行后见的逻辑

		- 场景

			- 多线程读取文件处理

	- CyclicBarrier（可循环使用的屏障）

		- 作用

			- 允许count个线程阻塞在一个地方，直至所有线程的任务都执行完毕，比CountDownLatch更复杂和强大

		- 原理

			- 基于ReentrantLock和Condition实现

			- await方法基于lock()加锁，扣减count值，当count值为0时继续执行后面的逻辑，重置count值为初始值

	- Semaphore(信号量)

		- 作用：控制同时访问特定资源的线程数量，同一时刻只能有N个线程访问资源

		- 两种模式(通过构造函数可以设置)

			- 公平模式，acquire()

			- 抢占式的

		- 原理

			- 默认构造AQS的state值为permits，即许可证的数量

			- 线程开始执行之初修改state值

			- 调用semaphore.acquire(),线程尝试获取许可证

				- 如果state>=0则表示可以获取成功，获取成功后使用CAS修改state=state-1

				- 如果state<0,则创建一个Node节点加入阻塞队列。

			- 调用semaphore.release()释放许可证，使用CAS修改state=state+1

		- 场景

			- 用于那些资源有明确访问数量的场景，如限流(仅限于单机),项目推荐使用Redis+Lua来做限流

## 线程池

### 作用

- 降低资源损耗,即线程创建和销毁造成的损耗

- 提高响应速度,即到即用

- 重复利用线程，节省资源

### 创建方式

- 通过ThreadPoolExecutor构造函数(推荐)

	- int corePoolSize:核心线程数

	- int maximumPoolSize:线程池最大线程数

	- long keepAliveTime:当线程数大于核心线程数时，多余空闲线程存活的最长时间

	- TimeUnit unit:时间单位

	- BlockingQueue<Runnable> workQueue:任务队列，用来存储等待执行任务的队列

		- SynchronousQueue

			- 直接将任务交给消费者，必须等队列中的添加元素被消费后才能继续添加新的元素。

			- 要求最大线程数为无界，避免线程拒绝执行操作

		- LinkedBlockingQueue

			- 无界缓存等待队列

			- 当前执行的线程数量达到 corePoolSize 的数量时，剩余的元素会在阻塞队列里等待

		- ArrayBlockingQueue

			- 有界缓存等待队列

	- threadFactory：线程工厂，这个参数主要用来创建线程；

	- ExecutionHandler handler:拒绝策略

		- ThreadPoolExecutor.AbortPolicy

			- 直接拒绝，抛出RejectedExcutionException拒绝新任务的处理（默认使用）

		- ThreadPoolExecutor.CallerRunsPolicy

			- 调用execute的线程运行任务,如果执行程序关闭则丢弃

		- ThreadPoolExecutor.DiscardPolicy

			- 不处理新任务，直接丢弃，不抛异常

		- ThreadPoolExecutor.DiscardOldestPolicy

			- 丢弃最早的未处理的请求

- 通过Executor框架的工具类Executors创建(不推荐)

	- FixedThreadPool

		- 固定线程数量

		- 无界任务队列，LinkedBlockingQueue,最大长度为Integer.MAX_VALUE

	- SingleThreadExecutor

		- 一个线程

		- 无界任务队列，LinkedBlockingQueue,最大长度为Integer.MAX_VALUE

	- CachedTreadPool

		- 可调整线程数量,允许创建的线程数为Integer_MAX_VALUE

		- 同步队列SynchronousQueue，没有容量

	- ScheduledThreadPool

		- 具有一定延时和周期性执行

		- 延迟阻塞队列

	- 不推荐使用这种方式创建线程池，这种方式创建出来的线程池可能会出现OOM问题

	- 阻塞队列和非阻塞队列

		- 阻塞队列

			- 提供了线程安全的方法，当队列为空时或已满时进行阻塞或等待操作

				- BlockingQueue

		- 非阻塞队列

			- 提供了线程安全的方法，当队列为空时或已满时不会进行阻塞或等待操作，而是返回特定值或抛出异常

				- ConcurrentLinkedQueue 

### 线程池状态

- RUNNING

	- 如果线程池处于 RUNNING 状态下的话，能够接收新任务，也能处理正在运行的任务。

- SHUTDOWN

	- 位于 SHUTDOWN 状态的线程池能够处理正在运行的任务，但是不能接受新的任务

- STOP

- TIDYING

	- 一种是是当线程池位于 SHUTDOWN 状态下，阻塞队列和线程池中的线程数量为空时，会由 SHUTDOWN -> TIDYING

	- 当线程池位于 STOP 状态下时，线程池中的数量为空时，会由 STOP -> TIDYING 状态。

- TERMINATED

	- 线程池处在 TIDYING 状态时，执行完terminated 方法之后，就会由 TIDYING -> TERMINATED 状态。此时表示线程池的彻底终止。

### 销毁方法

- shutdown() ExecutorService 会有序关闭正在执行的任务，但是不接受新任务。

- shutdownNow()会尝试停止关闭所有正在执行的任务，停止正在等待的任务，并返回正在等待执行的任务列表。

### 线程池处理任务的流程

-  

	- 如果当前运行的工作线程少于 corePoolSize 的话，那么会创建新线程来执行任务 ，这一步需要获取 mainLock 全局锁。

	- 如果运行线程不小于 corePoolSize，则将任务加入 BlockingQueue 阻塞队列。

	- 如果无法将任务加入 BlockingQueue 中，此时的现象就是队列已满，此时需要创建新的线程来处理任务，这一步同样需呀获取 mainLock 全局锁。

	- 如果创建新线程会使当前运行的线程超过 maximumPoolSize 的话，任务将被拒绝，并且使用RejectedExecutionHandler.rejectEExecution() 方法拒绝新的任务。

-  对于一个新创建的线程池，在没有分配线程任务时，线程池中的线程数为0，一旦有新任务，线程池就会创建一个新的线程执行任务，结束后该线程也不会被销毁，而是处于空闲的状态

### 设定线程池的大小

- 上下文切换成本

	- CPU采取的策略是为每个线程分配时间片并轮转的

	- 当前任务执行完CPU时间片切换到另一个任务之前会先保存自己的状态，以便下次在切换回这个任务时，可以再加载这个任务的状态。

	- 任务从保存到再加载的过程就是一次上下文切换

- 可能会出现的问题

	- 数量太小

		- 大量任务堆积 导致OOM

		- Cpu资源未充分利用

	- 数量太大

		- 大量线程竞争CPU资源，上下文切换成本高

- 设置公式

	- CPU密集型任务(N+1)：主要是消耗CPU资源，线程数量太多，会导致频繁的上下文切换

	- I/O密集型任务(2N)：系统大部分的时间来处理I/O交互，而线程在处理I/O时间段内不会占用CPU来处理。

		- 网络读取

		- 文件读取

- 设计一个根据任务优先级来执行的线程池

	- 使用PriorityBlockingQueue（优先级阻塞队列）

		- 底层通过二叉堆实现(小顶堆)，即值最小的元素优先出队

		- 实现排序的方式

			- 提交到线程池的任务实现Comparable接口

			- 传入Comparator对象来指定任务之间的排序规则(推荐)

		- 风险

			- 它是无界的，可能堆积大量请求，导致OOM

				- 解决方案: 重写offer方法，当插入元素数量超过指定值就返回false

			- 低优先级的任务长时间得不到执行

				- 解决方案：等待时间过长的任务会被移除并重新添加到队列中，但是优先级会被提升

			- 需要对队列中的元素进行排序以及保证线程安全，会降低性能

				- 无法避免，但是大部分业务场景可以接受

### 几个重要接口

- Runnable：线程中的任务需要实现该运行接口，才可在线程池中运行。



- Callable：Runnable实现的任务没有返回结果，Callable有异步回调结果



	-  

- Future: 提交任务至线程池后返回的结果



- CompletableFuture类

	- 异步任务编排组合

	- 函数式编程

## Atomicxxx

### AtomicInteger

- 内部维护了一个共享资源state，通过自旋CAS来维护state

- 但是当线程过多时，会导致CPU满载，所以应对这个问题可以采用分散热点的方式将热点值分散出去（引出LongAddr）

### LongAddr

- 它主要解决高并发环境下 AtomictLong 的自旋瓶颈问题

- cells数组

- 它通过将共享资源分散到Cells数组的各个槽位，每个线程针对自己的槽位进行CAS操作即可，最终只要将各个槽位的值累加起来就是结果了，但是它不能实时获取值

### AtomicStampedReference

- 它每次修改时都会用stamped版本号进行判断

